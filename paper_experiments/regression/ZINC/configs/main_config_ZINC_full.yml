datasets:
  - {
      name: "ZINC-full",
      task: "graph_regression",
      validation_folds: 1,
      with_splits: False,
      split_function: zinc_splits_full,
      experiment_config_file: "paper_experiments/regression/ZINC/configs/network_ZINC.yml",
      type: 'ZINC',
  }



paths:
  # all the paths are relative to the PYTHONPATH path, can be also defined dataset-wise in the experiment_config_file
  data:
    "paper_experiments/Data/Graphs/"
  properties:
    "paper_experiments/Data/Properties/" # Precomputed properties will be loaded from this folder
  labels:
    "paper_experiments/Data/Labels/" # Path to the folder containing the labels
  splits:
    "paper_experiments/Data/Splits/" # Path to the folder containing the data splits
  results:
    "paper_experiments/Results/regression/" # Results will be saved in this folder

device: cpu
mode: experiments # if debug printing and plotting options are enabled, for the experiments mode should be 'experiments'
precision: double

# network options

# optimizer: optimizer for the network
optimizer:
  - Adam


# loss: loss function for the network
loss:
  - MAE



# rule_occurrence_threshold: threshold for the rule occurrence, determines how often a rule has to be present to be used in the network
# -type: [graph, total], graph: the rule has to be present in a graph, total: the rule has to be present in the whole dataset
# -threshold: the threshold for the rule occurrence at least this many times
rule_occurrence_threshold: 2

# weight initialization: weight initialization for the network (TODO)
# - convolution: weight initialization for the convolutional layers
# - convolution_bias: weight initialization for the convolutional bias
# - aggregation: weight initialization for the aggregation layer
# - aggregation_bias: weight initialization for the aggregation bias
# keys:
#     - type: [uniform, normal, constant, lower_upper], uniform: uniform distribution, normal: normal distribution, constant: constant value, lower_upper: uniform distribution with lower and upper bound from the number of weights
#     - min: minimum value for the uniform distribution
#     - max: maximum value for the uniform distribution
#     - value: constant value for the constant distribution
#     - mean for the normal distribution
#     - std: variance for the normal distribution
weight_initialization: { convolution: {  type: 'lower_upper', value: -0.001 },
                         convolution_bias: { type: 'lower_upper', value: 0.0},
                         aggregation: {  type: 'lower_upper', value: -0.001 },
                         aggregation_bias: { type: 'lower_upper', value: 0.0 }}

batch_size:
  - 128
learning_rate:
  - 0.001
epochs:
  - 300

early_stopping:
  enabled:
    False
  patience:
    25


scheduler: { type: 'ReduceLROnPlateau', factor: 0.5, patience: 10, min_lr: 0.00001 }

# how to sample the training data
training_data_sampling: { type: 'default'}
#training_data_sampling: { type: 'curriculum', bucket_num: 5, anti: True, exclusive: True}
#training_data_sampling: { type: 'curriculum', bucket_num: 5, anti: True }
#training_data_sampling: { type: 'random' }

#input_features: {name: constant, value: 1.0}
#input_features: {name: constant, value: 1.0}
input_features: {name: node_labels, transformation: 'one_hot'}
#input_features: {name: node_features}
#use_feature_transformation: {out_dimension: 21, bias: True}
best_model: True

